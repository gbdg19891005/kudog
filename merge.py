#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Kudog M3U Merger - ç»ˆæç¨³å®šç‰ˆ
ä¿®å¤æ‰€æœ‰requestså’Œsources.jsonæ ¼å¼é—®é¢˜
"""

import logging
import os
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from typing import Dict, Any, List
from loader import loadconfig, loadsources, loadgroups, loadalias
from processor import process_lines, convert_txt_to_m3u
from exporter import export_m3u

def main():
    print("ğŸš€ Kudog M3U Merger v2.0 - Starting...")
    
    # === 1. åŠ è½½æ‰€æœ‰é…ç½® ===
    config = loadconfig()
    sources = loadsources()
    groups = loadgroups()
    aliasmap = loadalias()
    
    print(f"ğŸ“‹ Config: {config['outputfile']}")
    print(f"ğŸ“Š Sources: {len(sources.get('local_files', []))} local, {len(sources.get('remote_urls', []))} remote")
    print(f"ğŸ”‘ Aliases: {len(aliasmap)}")
    
    rules = groups.get('rules', {})
    customchannels = groups.get('customchannels', [])
    blocklist = groups.get('blocklist', [])
    grouporder = list(rules.keys())
    
    keep_multiple_urls = config['keepmultipleurls']
    timeout = config['timeout']
    epg = config['epg']
    default_group = config['defaultgroup']
    
    # === 2. é…ç½®æ—¥å¿— ===
    loglevel = getattr(logging, config.get('loglevel', 'INFO').upper(), logging.INFO)
    logging.basicConfig(level=loglevel, format='%(levelname)s %(message)s')
    
    channels: Dict[str, Any] = {}
    
    # === 3. å¤„ç†æœ¬åœ°æ–‡ä»¶ ===
    for fname in sources.get('local_files', []):
        if not isinstance(fname, str):
            logging.warning(f"âŒ INVALID LOCAL FILE: {fname}")
            continue
        if not os.path.exists(fname):
            logging.warning(f"âŒ FILE NOT FOUND: {fname}")
            continue
        try:
            with open(fname, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.read().splitlines()
            if not lines:
                logging.warning(f"âŒ EMPTY FILE: {fname}")
                continue
                
            first_line = lines[0].lstrip().strip().upper()
            if not first_line.startswith('#EXTM3U'):
                logging.info(f"ğŸ”„ Converting TXT to M3U: {fname}")
                lines = convert_txt_to_m3u(lines, default_group)
            
            process_lines(lines[1:], aliasmap, rules, blocklist, keep_multiple_urls, 
                         channels, primary=True, source_name=f"ğŸ“{fname}", 
                         default_group=default_group)
            logging.info(f"âœ“ LOCAL OK: {fname} ({len(lines)} lines)")
        except Exception as e:
            logging.error(f"âœ— LOCAL ERROR {fname}: {type(e).__name__}: {e}")
    
    # === 4. å¤„ç†è¿œç¨‹URLï¼ˆç»ˆæä¿®å¤ï¼‰ ===
    session = requests.Session()
    retry_strategy = Retry(
        total=3, 
        backoff_factor=1, 
        status_forcelist=[429, 500, 502, 503, 504]
    )
    adapter = HTTPAdapter(max_retries=retry_strategy, pool_connections=10, pool_maxsize=10)
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    
    processed_count = 0
    for idx, src in enumerate(sources.get('remote_urls', [])):
        try:
            # âœ… å…¼å®¹å„ç§sources.jsonæ ¼å¼
            if isinstance(src, str):
                url = src.strip()
                include_channels: List[str] = []
            elif isinstance(src, dict):
                url = src.get('url', '').strip()
                include_channels = src.get('include_channels', [])
                if not url:
                    logging.warning(f"âŒ EMPTY URL at index {idx}")
                    continue
            else:
                logging.warning(f"âŒ INVALID SOURCE at index {idx}: {type(src)}")
                continue
            
            headers = {
                'User-Agent': config['ua'],
                'Accept': 'text/plain,*/*',
                'Connection': 'keep-alive'
            }
            if config.get('referrer'):
                headers['Referer'] = config['referrer']
            
            logging.info(f"ğŸŒ Fetching ({idx+1}/{len(sources.get('remote_urls', []))}): {url}")
            
            # âœ… ç»ˆæä¿®å¤ï¼šsession.get() + å¼‚å¸¸å¤„ç†
            resp = session.get(url, headers=headers, timeout=timeout, stream=True)
            resp.raise_for_status()  # HTTPçŠ¶æ€æ£€æŸ¥
            
            text = resp.text.strip()
            if not text:
                logging.warning(f"âŒ EMPTY RESPONSE: {url}")
                continue
                
            lines = text.splitlines()
            if not lines:
                logging.warning(f"âŒ NO LINES: {url}")
                continue
                
            first_line = lines[0].lstrip().strip().upper()
            if not first_line.startswith('#EXTM3U'):
                logging.info(f"ğŸ”„ Converting TXT: {url}")
                lines = convert_txt_to_m3u(lines, default_group)
            
            process_lines(lines[1:], aliasmap, rules, blocklist, keep_multiple_urls, 
                         channels, primary=False, source_name=f"ğŸŒ{url}", 
                         default_group=default_group, whitelist=include_channels)
            
            processed_count += 1
            logging.info(f"âœ“ REMOTE OK ({processed_count}): {url}")
            
        except requests.exceptions.Timeout:
            logging.warning(f"â° TIMEOUT ({idx+1}): {url}")
        except requests.exceptions.HTTPError as e:
            logging.warning(f"ğŸ“¡ HTTP {e.response.status_code} ({idx+1}): {url}")
        except requests.exceptions.RequestException as e:
            logging.warning(f"ğŸ“¡ REQUEST ERROR ({idx+1}): {url} - {str(e)}")
        except Exception as e:
            logging.error(f"ğŸ’¥ CRITICAL ({idx+1}): {url} - {type(e).__name__}: {str(e)}")
    
    # === 5. å¯¼å‡ºç»“æœ ===
    export_m3u(channels, customchannels, grouporder, epg, keep_multiple_urls,
               outfile=config['outputfile'], 
               generatedebugfile=config['generatedebugfile'],
               defaultgroup=default_group)
    
    total = len(channels)
    print(f"\nğŸ‰ SUCCESS! {total} unique channels â†’ {config['outputfile']}")
    logging.info(f"ğŸ“Š FINAL: {total} channels from {processed_count} sources")

if __name__ == '__main__':
    main()
